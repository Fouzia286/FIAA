# chatbot.py
import streamlit as st
import os
import requests
from dotenv import load_dotenv

# Load environment variables from .env
load_dotenv()

# Groq API Key from .env
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

# Groq API URL and headers
GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"
HEADERS = {
    "Authorization": f"Bearer {GROQ_API_KEY}",
    "Content-Type": "application/json"
}

# Function to talk to Groq API
def chat_with_groq(messages, model="llama3-8b-8192"):
    body = {
        "model": model,
        "messages": messages,
        "temperature": 0.7
    }
    response = requests.post(GROQ_API_URL, headers=HEADERS, json=body)
    if response.status_code == 200:
        return response.json()["choices"][0]["message"]["content"]
    else:
        return f"‚ùå Error {response.status_code}: {response.text}"

# Streamlit UI
st.set_page_config(page_title="Chatbot")
st.title("ü§ñ FIAA-Chatbot")

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": "You are a helpful AI assistant."}
    ]

# Display conversation
for msg in st.session_state.messages[1:]:
    st.chat_message(msg["role"]).markdown(msg["content"])

# User input
if prompt := st.chat_input("Ask me anything..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").markdown(prompt)

    with st.chat_message("assistant"):
        response = chat_with_groq(st.session_state.messages)
        st.markdown(response)
    st.session_state.messages.append({"role": "assistant", "content": response})
